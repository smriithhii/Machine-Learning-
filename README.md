# Machine-Learning-

This repository is dedicated to comparing the results of using 3 classification algorithms in machine learning, which was done as a credit of our machine learning course this semester by me and my teammates. 

Problem Statement

Performing classification on Big malware dataset from microsoft to produce the output variable ‘Class’.

Abstract
Objective: Comparative analysis of classification algorithms (XGBoost, AdaBoost, Random Forest) on a specific dataset for accurate class label prediction.
Dataset: Contains features and class labels, suitable for classification tasks. The dataset could be obtained from (https://www.kaggle.com/datasets/muhammad4hmed/malwaremicrosoftbig/data).
Data Preprocessing: Handling missing values & Feature Engineering
Data Split: Divide the dataset into training and testing sets.
Algorithms: 
 Random Forest: Utilizes a forest of decision trees.
AdaBoost and XGBoost: Implement boosting techniques to improve accuracy.
Comparative Analysis Metrics:
Accuracy.
Precision.
Recall.
F1-score.
Purpose: Assess the performance of each algorithm and identify any significant differences in results.
Efficiency Evaluation: Computational efficiency & Training times of each model.

To understand more about this refer to our medium blog on : 
